{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl_7PqM9Q5QY",
        "colab_type": "text"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P59NYU98GCb9",
        "colab": {}
      },
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip3 -qq install bokeh==0.13.0\n",
        "!pip3 -qq install gensim==3.6.0\n",
        "!pip3 -qq install nltk\n",
        "!pip3 -qq install scikit-learn==0.20.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8sVtGHmA9aBM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TiA2dGmgF1rW",
        "outputId": "aeebff95-2211-4faf-884e-219de104ca8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QstS4NO0L97c",
        "outputId": "9ef634ed-ed6f-455b-9404-31cf864c29b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTai8Ta0lgwL",
        "outputId": "d123bf08-df90-4a24-9369-c71dfadd8548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCjwwDs6Zq9x",
        "outputId": "4b2a0920-7d8b-4a04-aa0e-247d850b4144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in train = 45441. Tags = {'VERB', 'DET', 'PRON', 'ADV', 'X', 'ADJ', 'NUM', 'ADP', 'PRT', 'NOUN', '.', 'CONJ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URC1B2nvPGFt",
        "outputId": "2baea43c-a43e-4900-8d1e-d7bfa49dd1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rWmSToIaeAo",
        "outputId": "f78ac666-8e01-4c06-89b3-68a3aef823ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjz_Rk0bbMyH",
        "outputId": "2040adb0-b05b-4b5e-8775-2e5339b00efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XCuxEBVbOY_",
        "outputId": "7299d26b-9112-47f1-9ede-4283751c6609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of trigram tagger = 23.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtRbz1SwgEqc",
        "colab": {}
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhsTKZalfih6",
        "colab": {}
      },
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4XsRII5kW5x",
        "outputId": "c99b2cac-f21d-4f7a-8457-211cb17b32f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((23, 4), (23, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WVEHju54d68T",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=word_emb_dim,\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=lstm_layers_count\n",
        "        )\n",
        "        self.classifier = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_sentence(inputs):\n",
        "        result = []\n",
        "        for i in range(inputs.shape[1]):\n",
        "            temp = []\n",
        "            j = 0\n",
        "            while j < inputs.shape[0]:\n",
        "                temp.append(inputs[j, i])\n",
        "                j += 1\n",
        "            result.append(torch.LongTensor(temp).cuda())\n",
        "        return result\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        sentences = LSTMTagger.build_sentence(inputs)\n",
        "        result = []\n",
        "        for sentence in sentences:\n",
        "            embeds = self.encoder(sentence)\n",
        "            lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "            tag_space = self.classifier(lstm_out.view(len(sentence), -1))\n",
        "            tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "            result.append(tag_scores)\n",
        "\n",
        "        return torch.stack(result).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggXrywJpY-QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_accuracy(predictions, ground_truth):\n",
        "    return float(torch.sum((torch.transpose(torch.argmax(predictions, dim=2), dim0=0, dim1=1) == ground_truth) * (ground_truth != 0))),  float(torch.sum(ground_truth != 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbrxsZ2mehWB",
        "outputId": "95f74deb-dab9-4d00-9378-3db70e85f383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch).cuda(), torch.LongTensor(y_batch).cuda()\n",
        "\n",
        "logits = model(X_batch)\n",
        "\n",
        "calculate_accuracy(logits, y_batch)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.0, 69.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMUyUm1hgpe3",
        "outputId": "dfb363f9-bd00-4493-ff4d-9d705bc232bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "criterion(torch.transpose(logits, dim0=0, dim1=1).reshape((-1, logits.shape[2])), y_batch.reshape((-1)))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5497, device='cuda:0', grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FprPQ0gllo7b",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0.0\n",
        "    sum_count = 0.0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch).cuda(), LongTensor(y_batch).cuda()\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = criterion(torch.transpose(logits, dim0=0, dim1=1).reshape((-1, logits.shape[2])), y_batch.reshape((-1)))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                cur_correct_count, cur_sum_count = calculate_accuracy(logits, y_batch)\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), float(cur_correct_count) / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, float(correct_count) / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, float(correct_count) / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pqfbeh1ltEYa",
        "outputId": "8123daa8-b39a-4ba3-dd9a-24036423cfaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.32228, Accuracy = 71.64%: 100%|██████████| 572/572 [02:31<00:00,  3.79it/s]\n",
            "[1 / 10]   Val: Loss = 0.10070, Accuracy = 85.35%: 100%|██████████| 13/13 [00:23<00:00,  1.80s/it]\n",
            "[2 / 10] Train: Loss = 0.10040, Accuracy = 90.05%: 100%|██████████| 572/572 [02:31<00:00,  3.77it/s]\n",
            "[2 / 10]   Val: Loss = 0.07599, Accuracy = 89.66%: 100%|██████████| 13/13 [00:23<00:00,  1.80s/it]\n",
            "[3 / 10] Train: Loss = 0.06758, Accuracy = 93.26%: 100%|██████████| 572/572 [02:31<00:00,  3.77it/s]\n",
            "[3 / 10]   Val: Loss = 0.06938, Accuracy = 91.27%: 100%|██████████| 13/13 [00:22<00:00,  1.77s/it]\n",
            "[4 / 10] Train: Loss = 0.05114, Accuracy = 94.83%: 100%|██████████| 572/572 [02:34<00:00,  3.71it/s]\n",
            "[4 / 10]   Val: Loss = 0.06408, Accuracy = 91.99%: 100%|██████████| 13/13 [00:24<00:00,  1.86s/it]\n",
            "[5 / 10] Train: Loss = 0.04048, Accuracy = 95.84%: 100%|██████████| 572/572 [02:34<00:00,  3.70it/s]\n",
            "[5 / 10]   Val: Loss = 0.06002, Accuracy = 92.57%: 100%|██████████| 13/13 [00:23<00:00,  1.84s/it]\n",
            "[6 / 10] Train: Loss = 0.03303, Accuracy = 96.60%: 100%|██████████| 572/572 [02:34<00:00,  3.70it/s]\n",
            "[6 / 10]   Val: Loss = 0.06664, Accuracy = 92.96%: 100%|██████████| 13/13 [00:23<00:00,  1.80s/it]\n",
            "[7 / 10] Train: Loss = 0.02717, Accuracy = 97.17%: 100%|██████████| 572/572 [02:34<00:00,  3.71it/s]\n",
            "[7 / 10]   Val: Loss = 0.06663, Accuracy = 93.10%: 100%|██████████| 13/13 [00:24<00:00,  1.85s/it]\n",
            "[8 / 10] Train: Loss = 0.02264, Accuracy = 97.65%: 100%|██████████| 572/572 [02:34<00:00,  3.71it/s]\n",
            "[8 / 10]   Val: Loss = 0.06762, Accuracy = 93.20%: 100%|██████████| 13/13 [00:23<00:00,  1.84s/it]\n",
            "[9 / 10] Train: Loss = 0.01888, Accuracy = 98.04%: 100%|██████████| 572/572 [02:33<00:00,  3.72it/s]\n",
            "[9 / 10]   Val: Loss = 0.06850, Accuracy = 93.20%: 100%|██████████| 13/13 [00:23<00:00,  1.80s/it]\n",
            "[10 / 10] Train: Loss = 0.01561, Accuracy = 98.38%: 100%|██████████| 572/572 [02:33<00:00,  3.72it/s]\n",
            "[10 / 10]   Val: Loss = 0.07455, Accuracy = 93.27%: 100%|██████████| 13/13 [00:23<00:00,  1.81s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98wr38_rw55D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "cc7050f4-cfe4-44c6-ee8d-2276f9e5738e"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.68775, Accuracy = 78.02%: 100%|██████████| 572/572 [02:34<00:00,  3.70it/s]\n",
            "[1 / 10]   Val: Loss = 0.35328, Accuracy = 88.02%: 100%|██████████| 13/13 [00:23<00:00,  1.84s/it]\n",
            "[2 / 10] Train: Loss = 0.27468, Accuracy = 90.88%: 100%|██████████| 572/572 [02:32<00:00,  3.75it/s]\n",
            "[2 / 10]   Val: Loss = 0.23847, Accuracy = 91.63%: 100%|██████████| 13/13 [00:23<00:00,  1.78s/it]\n",
            "[3 / 10] Train: Loss = 0.18604, Accuracy = 93.82%: 100%|██████████| 572/572 [02:33<00:00,  3.72it/s]\n",
            "[3 / 10]   Val: Loss = 0.19285, Accuracy = 93.18%: 100%|██████████| 13/13 [00:22<00:00,  1.72s/it]\n",
            "[4 / 10] Train: Loss = 0.13882, Accuracy = 95.38%: 100%|██████████| 572/572 [02:33<00:00,  3.73it/s]\n",
            "[4 / 10]   Val: Loss = 0.17466, Accuracy = 93.69%: 100%|██████████| 13/13 [00:24<00:00,  1.87s/it]\n",
            "[5 / 10] Train: Loss = 0.10841, Accuracy = 96.36%: 100%|██████████| 572/572 [02:32<00:00,  3.75it/s]\n",
            "[5 / 10]   Val: Loss = 0.16504, Accuracy = 94.05%: 100%|██████████| 13/13 [00:23<00:00,  1.84s/it]\n",
            "[6 / 10] Train: Loss = 0.08625, Accuracy = 97.09%: 100%|██████████| 572/572 [02:32<00:00,  3.74it/s]\n",
            "[6 / 10]   Val: Loss = 0.17108, Accuracy = 94.17%: 100%|██████████| 13/13 [00:24<00:00,  1.91s/it]\n",
            "[7 / 10] Train: Loss = 0.06971, Accuracy = 97.65%: 100%|██████████| 572/572 [02:35<00:00,  3.69it/s]\n",
            "[7 / 10]   Val: Loss = 0.16832, Accuracy = 94.31%: 100%|██████████| 13/13 [00:23<00:00,  1.83s/it]\n",
            "[8 / 10] Train: Loss = 0.05673, Accuracy = 98.10%: 100%|██████████| 572/572 [02:32<00:00,  3.74it/s]\n",
            "[8 / 10]   Val: Loss = 0.16786, Accuracy = 94.48%: 100%|██████████| 13/13 [00:23<00:00,  1.81s/it]\n",
            "[9 / 10] Train: Loss = 0.04626, Accuracy = 98.45%: 100%|██████████| 572/572 [02:32<00:00,  3.76it/s]\n",
            "[9 / 10]   Val: Loss = 0.18062, Accuracy = 94.37%: 100%|██████████| 13/13 [00:24<00:00,  1.85s/it]\n",
            "[10 / 10] Train: Loss = 0.03798, Accuracy = 98.73%: 100%|██████████| 572/572 [02:30<00:00,  3.80it/s]\n",
            "[10 / 10]   Val: Loss = 0.18744, Accuracy = 94.43%: 100%|██████████| 13/13 [00:23<00:00,  1.77s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isrcFBU5Q5R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BidirectionalLSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.h_size = lstm_hidden_dim\n",
        "        self.encoder = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=word_emb_dim,\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=lstm_layers_count,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.classifier = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_sentence(inputs):\n",
        "        result = []\n",
        "        for i in range(inputs.shape[1]):\n",
        "            temp = []\n",
        "            j = 0\n",
        "            while j < inputs.shape[0]:\n",
        "                temp.append(inputs[j, i])\n",
        "                j += 1\n",
        "            result.append(torch.LongTensor(temp).cuda())\n",
        "        return result\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        sentences = LSTMTagger.build_sentence(inputs)\n",
        "        result = []\n",
        "        for sentence in sentences:\n",
        "            embeds = self.encoder(sentence)\n",
        "            lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "\n",
        "            forward_output, backward_output = lstm_out[:, :, :self.h_size], lstm_out[:, :, self.h_size:]\n",
        "            staggered_output = forward_output + backward_output\n",
        "\n",
        "            tag_space = self.classifier(staggered_output.view(len(sentence), -1))\n",
        "            tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "            result.append(tag_scores)\n",
        "\n",
        "        return torch.stack(result).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTqtcos9g1SE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "93a21124-0e8b-4123-8f6e-f239a99ad295"
      },
      "source": [
        "model = BidirectionalLSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.54039, Accuracy = 82.74%: 100%|██████████| 572/572 [03:51<00:00,  2.47it/s]\n",
            "[1 / 10]   Val: Loss = 0.27178, Accuracy = 91.09%: 100%|██████████| 13/13 [00:33<00:00,  2.56s/it]\n",
            "[2 / 10] Train: Loss = 0.20029, Accuracy = 93.64%: 100%|██████████| 572/572 [03:50<00:00,  2.48it/s]\n",
            "[2 / 10]   Val: Loss = 0.17653, Accuracy = 94.32%: 100%|██████████| 13/13 [00:33<00:00,  2.57s/it]\n",
            "[3 / 10] Train: Loss = 0.12618, Accuracy = 96.07%: 100%|██████████| 572/572 [03:53<00:00,  2.45it/s]\n",
            "[3 / 10]   Val: Loss = 0.14164, Accuracy = 95.45%: 100%|██████████| 13/13 [00:32<00:00,  2.53s/it]\n",
            "[4 / 10] Train: Loss = 0.08538, Accuracy = 97.40%: 100%|██████████| 572/572 [03:55<00:00,  2.43it/s]\n",
            "[4 / 10]   Val: Loss = 0.12721, Accuracy = 95.80%: 100%|██████████| 13/13 [00:34<00:00,  2.66s/it]\n",
            "[5 / 10] Train: Loss = 0.05821, Accuracy = 98.27%: 100%|██████████| 572/572 [03:53<00:00,  2.45it/s]\n",
            "[5 / 10]   Val: Loss = 0.11844, Accuracy = 96.24%: 100%|██████████| 13/13 [00:31<00:00,  2.42s/it]\n",
            "[6 / 10] Train: Loss = 0.03939, Accuracy = 98.86%: 100%|██████████| 572/572 [03:52<00:00,  2.46it/s]\n",
            "[6 / 10]   Val: Loss = 0.11800, Accuracy = 96.27%: 100%|██████████| 13/13 [00:33<00:00,  2.57s/it]\n",
            "[7 / 10] Train: Loss = 0.02573, Accuracy = 99.30%: 100%|██████████| 572/572 [03:53<00:00,  2.45it/s]\n",
            "[7 / 10]   Val: Loss = 0.12399, Accuracy = 96.22%: 100%|██████████| 13/13 [00:32<00:00,  2.52s/it]\n",
            "[8 / 10] Train: Loss = 0.01650, Accuracy = 99.58%: 100%|██████████| 572/572 [03:53<00:00,  2.45it/s]\n",
            "[8 / 10]   Val: Loss = 0.13118, Accuracy = 96.29%: 100%|██████████| 13/13 [00:33<00:00,  2.56s/it]\n",
            "[9 / 10] Train: Loss = 0.01024, Accuracy = 99.77%: 100%|██████████| 572/572 [03:54<00:00,  2.44it/s]\n",
            "[9 / 10]   Val: Loss = 0.13296, Accuracy = 96.35%: 100%|██████████| 13/13 [00:34<00:00,  2.64s/it]\n",
            "[10 / 10] Train: Loss = 0.00623, Accuracy = 99.88%: 100%|██████████| 572/572 [03:54<00:00,  2.44it/s]\n",
            "[10 / 10]   Val: Loss = 0.15001, Accuracy = 96.15%: 100%|██████████| 13/13 [00:32<00:00,  2.50s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZpY_Q1xZ18h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "00ff1d79-09c7-4d97-f9d9-2840e7f8f064"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[===============================================---] 94.2% 120.7/128.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsCstxiO03oT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f1773be-30e1-43c9-b21c-91dbb5333024"
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Know 38736 out of 45441 word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxaRBpQd0pat",
        "colab": {}
      },
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.h_size = lstm_hidden_dim\n",
        "        self.encoder = nn.Embedding.from_pretrained(torch.Tensor(embeddings))\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embeddings.shape[1],\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=lstm_layers_count,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.classifier = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "        \n",
        "\n",
        "    @staticmethod\n",
        "    def build_sentence(inputs):\n",
        "        result = []\n",
        "        for i in range(inputs.shape[1]):\n",
        "            temp = []\n",
        "            j = 0\n",
        "            while j < inputs.shape[0]:\n",
        "                temp.append(inputs[j, i])\n",
        "                j += 1\n",
        "            result.append(torch.LongTensor(temp).cuda())\n",
        "        return result\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        sentences = LSTMTagger.build_sentence(inputs)\n",
        "        result = []\n",
        "        for sentence in sentences:\n",
        "            embeds = self.encoder(sentence)\n",
        "            lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "\n",
        "            forward_output, backward_output = lstm_out[:, :, :self.h_size], lstm_out[:, :, self.h_size:]\n",
        "            staggered_output = forward_output + backward_output\n",
        "\n",
        "            tag_space = self.classifier(staggered_output.view(len(sentence), -1))\n",
        "            tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "            result.append(tag_scores)\n",
        "\n",
        "        return torch.stack(result).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBtI6BDE-Fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "7254042a-9cd5-491d-9aae-f79614a12799"
      },
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.54803, Accuracy = 83.96%: 100%|██████████| 572/572 [03:48<00:00,  2.50it/s]\n",
            "[1 / 10]   Val: Loss = 0.24780, Accuracy = 92.68%: 100%|██████████| 13/13 [00:33<00:00,  2.57s/it]\n",
            "[2 / 10] Train: Loss = 0.18295, Accuracy = 94.61%: 100%|██████████| 572/572 [03:50<00:00,  2.48it/s]\n",
            "[2 / 10]   Val: Loss = 0.17025, Accuracy = 94.94%: 100%|██████████| 13/13 [00:33<00:00,  2.59s/it]\n",
            "[3 / 10] Train: Loss = 0.13084, Accuracy = 96.09%: 100%|██████████| 572/572 [03:51<00:00,  2.47it/s]\n",
            "[3 / 10]   Val: Loss = 0.13829, Accuracy = 95.77%: 100%|██████████| 13/13 [00:33<00:00,  2.54s/it]\n",
            "[4 / 10] Train: Loss = 0.10553, Accuracy = 96.81%: 100%|██████████| 572/572 [03:53<00:00,  2.45it/s]\n",
            "[4 / 10]   Val: Loss = 0.12115, Accuracy = 96.30%: 100%|██████████| 13/13 [00:33<00:00,  2.55s/it]\n",
            "[5 / 10] Train: Loss = 0.09047, Accuracy = 97.25%: 100%|██████████| 572/572 [03:51<00:00,  2.47it/s]\n",
            "[5 / 10]   Val: Loss = 0.11181, Accuracy = 96.51%: 100%|██████████| 13/13 [00:33<00:00,  2.58s/it]\n",
            "[6 / 10] Train: Loss = 0.08050, Accuracy = 97.55%: 100%|██████████| 572/572 [03:50<00:00,  2.48it/s]\n",
            "[6 / 10]   Val: Loss = 0.10769, Accuracy = 96.55%: 100%|██████████| 13/13 [00:33<00:00,  2.58s/it]\n",
            "[7 / 10] Train: Loss = 0.07318, Accuracy = 97.76%: 100%|██████████| 572/572 [03:49<00:00,  2.49it/s]\n",
            "[7 / 10]   Val: Loss = 0.10182, Accuracy = 96.81%: 100%|██████████| 13/13 [00:33<00:00,  2.60s/it]\n",
            "[8 / 10] Train: Loss = 0.06722, Accuracy = 97.93%: 100%|██████████| 572/572 [03:49<00:00,  2.49it/s]\n",
            "[8 / 10]   Val: Loss = 0.09791, Accuracy = 96.91%: 100%|██████████| 13/13 [00:32<00:00,  2.47s/it]\n",
            "[9 / 10] Train: Loss = 0.06245, Accuracy = 98.05%: 100%|██████████| 572/572 [03:50<00:00,  2.48it/s]\n",
            "[9 / 10]   Val: Loss = 0.09617, Accuracy = 96.97%: 100%|██████████| 13/13 [00:33<00:00,  2.60s/it]\n",
            "[10 / 10] Train: Loss = 0.05856, Accuracy = 98.18%: 100%|██████████| 572/572 [03:50<00:00,  2.48it/s]\n",
            "[10 / 10]   Val: Loss = 0.09726, Accuracy = 96.94%: 100%|██████████| 13/13 [00:32<00:00,  2.52s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPUuAPGhEGVR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb42efd9-0773-4542-ade3-fbed89d3c462"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "batches_count = math.ceil(len(X_test) / 512)\n",
        "correct_count = 0.0\n",
        "sum_count = 0.0\n",
        "with tqdm(total=batches_count) as progress_bar:\n",
        "    for i, (X_batch, y_batch) in enumerate(iterate_batches((X_test, y_test), 512)):\n",
        "        X_batch, y_batch = LongTensor(X_batch).cuda(), LongTensor(y_batch).cuda()\n",
        "        logits = model(X_batch)\n",
        "\n",
        "        cur_correct_count, cur_sum_count = calculate_accuracy(logits, y_batch)\n",
        "\n",
        "        correct_count += cur_correct_count\n",
        "        sum_count += cur_sum_count\n",
        "\n",
        "        progress_bar.update()\n",
        "        progress_bar.set_description('{:>5s} Accuracy = {:.2%}'.format(\n",
        "            'Test', float(cur_correct_count) / cur_sum_count)\n",
        "        )\n",
        "            \n",
        "    progress_bar.set_description('{:>5s} Accuracy = {:.2%}'.format(\n",
        "        'Test', float(correct_count) / sum_count)\n",
        "    )"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Test Accuracy = 96.97%: 100%|██████████| 28/28 [01:08<00:00,  2.45s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMhfugH34zMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}